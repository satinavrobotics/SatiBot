{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc11dc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2663aa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as display\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "# 0 = all messages are logged (default behavior)\n",
    "# 1 = INFO messages are not printed\n",
    "# 2 = INFO and WARNING messages are not printed\n",
    "# 3 = INFO, WARNING, and ERROR messages are not printed\n",
    "\n",
    "#On Mac you may encounter an error related to OMP, this is a workaround, but slows down the code\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True' #https://github.com/dmlc/xgboost/issues/1715"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cfbf765",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "229760d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openbot import dataloader, data_augmentation, tfrecord_utils, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c41e26c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "531e95bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.0'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a14b768",
   "metadata": {},
   "source": [
    "## Set train and test dirs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0cf5a1",
   "metadata": {},
   "source": [
    "Define the dataset directory and give it a name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f6b4f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"/home/marcelsantos/Documents/OpenBotData(copy)\"\n",
    "dataset_name = \"my_openbot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b2512fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_from_tf_record = True\n",
    "if (load_from_tf_record):\n",
    "    train_data_dir = os.path.join(dataset_dir, \"tfrecords/train.tfrec\")\n",
    "    test_data_dir = os.path.join(dataset_dir, \"tfrecords/test.tfrec\")\n",
    "else:\n",
    "    train_data_dir = os.path.join(dataset_dir, \"train_data\")\n",
    "    test_data_dir = os.path.join(dataset_dir, \"test_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f318f45e",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5c2146",
   "metadata": {},
   "source": [
    "You may have to tune the learning rate and batch size depending on your available compute resources and dataset. As a general rule of thumb, if you increase the batch size by a factor of n, you can increase the learning rate by a factor of sqrt(n). For debugging and hyperparamter tuning, you can set the number of epochs to a small value like 10. If you want to train a model which will achieve good performance, you should set it to 50 or more. In our paper we used 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f61f0357",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 16 #128\n",
    "TEST_BATCH_SIZE = 16 #128\n",
    "LR = 0.0001 #0.0003\n",
    "NUM_EPOCHS = 10 #100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7c8bbf",
   "metadata": {},
   "source": [
    "Don't change these unless you know what you are doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e073ffd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "BN = True\n",
    "FLIP_AUG = False\n",
    "CMD_AUG = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff123dc8",
   "metadata": {},
   "source": [
    "## Load using `tf.data`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74ad23f",
   "metadata": {},
   "source": [
    "If training with tfrecord data, it will load the training and testing records and created the correspondiong `tf.data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "963ea8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape:  (96, 256, 3)\n",
      "Command:  0.0\n",
      "Label:  [0.29411766 0.29411766]\n",
      "Number of training instances:  15268\n",
      "Number of test instances:  14315\n"
     ]
    }
   ],
   "source": [
    "if load_from_tf_record:\n",
    "    def process_train_sample(features):\n",
    "        image = features[\"image\"]\n",
    "        cmd  = features[\"cmd\"]\n",
    "        label = [features[\"left\"], features[\"right\"]]\n",
    "        image = data_augmentation.augment_img(image)\n",
    "        if FLIP_AUG:\n",
    "            img, cmd, label = data_augmentation.flip_sample(img, cmd, label)\n",
    "        if CMD_AUG:\n",
    "            cmd = data_augmentation.augment_cmd(cmd)\n",
    "\n",
    "        return (image, cmd), label\n",
    "\n",
    "    def process_test_sample(features):\n",
    "        image = features[\"image\"]\n",
    "        cmd = features[\"cmd\"]\n",
    "        label = [features[\"left\"], features[\"right\"]]\n",
    "        return (image, cmd), label\n",
    "\n",
    "    train_dataset = ( \n",
    "        tf.data.TFRecordDataset(train_data_dir, num_parallel_reads=AUTOTUNE)\n",
    "        .map(tfrecord_utils.parse_tfrecord_fn, num_parallel_calls=AUTOTUNE)\n",
    "        .map(process_train_sample, num_parallel_calls=AUTOTUNE)\n",
    "    )\n",
    "\n",
    "    # Obtains the images shapes of records from .tfrecords.\n",
    "    for (image, cmd), label in train_dataset.take(1):\n",
    "        shape = image.numpy().shape\n",
    "        NETWORK_IMG_HEIGHT = shape[0]\n",
    "        NETWORK_IMG_WIDTH = shape[1]\n",
    "        print(\"Image shape: \", shape)\n",
    "        print(\"Command: \", cmd.numpy())\n",
    "        print(\"Label: \", label.numpy())\n",
    "\n",
    "    test_dataset = (\n",
    "        tf.data.TFRecordDataset(test_data_dir, num_parallel_reads=AUTOTUNE)\n",
    "        .map(tfrecord_utils.parse_tfrecord_fn, num_parallel_calls=AUTOTUNE)\n",
    "        .map(process_test_sample, num_parallel_calls=AUTOTUNE)\n",
    "    )\n",
    "\n",
    "    # Obtains the total number of records from .tfrecords file\n",
    "    # https://stackoverflow.com/questions/40472139/obtaining-total-number-of-records-from-tfrecords-file-in-tensorflow\n",
    "    image_count_train = sum(1 for _ in train_dataset)\n",
    "    print (\"Number of training instances: \", image_count_train)\n",
    "\n",
    "    image_count_test = sum(1 for _ in test_dataset)\n",
    "    print (\"Number of test instances: \", image_count_test)\n",
    "\n",
    "    # Prepare train and test datasets for training\n",
    "    train_ds = (\n",
    "        train_dataset.shuffle(TRAIN_BATCH_SIZE * 10)\n",
    "        .repeat()\n",
    "        .batch(TRAIN_BATCH_SIZE)\n",
    "        .prefetch(AUTOTUNE)\n",
    "    )\n",
    "\n",
    "    test_ds = test_dataset.batch(TEST_BATCH_SIZE).prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f10c70",
   "metadata": {},
   "source": [
    "If not using tfrecord"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b80a5e",
   "metadata": {},
   "source": [
    "Running this for the first time will take some time. This code will match image frames to the controls (labels) and indicator signals (commands).  By default, data samples where the vehicle was stationary will be removed. If this is not desired, you need to pass `remove_zeros=False`. If you have made any changes to the sensor files, changed `remove_zeros` or moved your dataset to a new directory, you need to pass `redo_matching=True`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cb567fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openbot import associate_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8241bdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not load_from_tf_record:\n",
    "    def process_train_path(file_path):\n",
    "        cmd, label = train_data.get_label(\n",
    "            tf.strings.regex_replace(file_path, \"[/\\\\\\\\]\", \"/\")\n",
    "        )\n",
    "        img = utils.load_img(file_path)\n",
    "        img = data_augmentation.augment_img(img)\n",
    "        if FLIP_AUG:\n",
    "            img, cmd, label = data_augmentation.flip_sample(img, cmd, label)\n",
    "        if CMD_AUG:\n",
    "            cmd = data_augmentation.augment_cmd(cmd)\n",
    "        return (img, cmd), label\n",
    "\n",
    "    def process_test_path(file_path):\n",
    "        cmd, label = test_data.get_label(\n",
    "            tf.strings.regex_replace(file_path, \"[/\\\\\\\\]\", \"/\")\n",
    "        )\n",
    "        img = utils.load_img(file_path)\n",
    "        return (img, cmd), label\n",
    "    \n",
    "    train_datasets = utils.list_dirs(train_data_dir)\n",
    "    test_datasets = utils.list_dirs(test_data_dir)\n",
    "    \n",
    "    max_offset = 1e3\n",
    "    train_frames = associate_frames.match_frame_ctrl_cmd(\n",
    "        train_data_dir,\n",
    "        train_datasets,\n",
    "        max_offset,\n",
    "        redo_matching=False,\n",
    "        remove_zeros=True,\n",
    "    )\n",
    "    test_frames = associate_frames.match_frame_ctrl_cmd(\n",
    "        test_data_dir,\n",
    "        test_datasets,\n",
    "        max_offset,\n",
    "        redo_matching=False,\n",
    "        remove_zeros=True,\n",
    "    )\n",
    "\n",
    "    image_count_train = len(train_frames)\n",
    "    image_count_test = len(test_frames)\n",
    "    \n",
    "    # To load the files as a `tf.data.Dataset` first create a dataset of the file paths. \n",
    "    # Depending on dataset size, this may take some time. If you encounter issues, you can use the \n",
    "    # commented lines instead. However, this will take **much** longer.\n",
    "    \n",
    "    # list_train_ds = tf.data.Dataset.list_files(train_frames)\n",
    "    # list_test_ds = tf.data.Dataset.list_files(test_frames)\n",
    "    \n",
    "    list_train_ds = tf.data.Dataset.list_files(\n",
    "        [str(train_data_dir + \"/\" + ds + \"/*/images/*\") for ds in train_datasets]\n",
    "    )\n",
    "    list_test_ds = tf.data.Dataset.list_files(\n",
    "        [str(test_data_dir + \"/\" + ds + \"/*/images/*\") for ds in test_datasets]\n",
    "    )\n",
    "    \n",
    "    train_data = dataloader.dataloader(train_data_dir, train_datasets)\n",
    "    test_data = dataloader.dataloader(test_data_dir, test_datasets)\n",
    "    \n",
    "    # Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
    "    labeled_ds = list_train_ds.map(process_train_path, num_parallel_calls=4)\n",
    "    for (image, cmd), label in labeled_ds.take(1):\n",
    "        shape = image.numpy().shape\n",
    "        NETWORK_IMG_HEIGHT = shape[0]\n",
    "        NETWORK_IMG_WIDTH = shape[1]\n",
    "        print(\"Image shape: \", shape)\n",
    "        print(\"Command: \", cmd.numpy())\n",
    "        print(\"Label: \", label.numpy())\n",
    "    \n",
    "    train_ds = utils.prepare_for_training(\n",
    "        ds=labeled_ds,\n",
    "        batch_sz=TRAIN_BATCH_SIZE,\n",
    "        shuffle_buffer_sz=100 * TRAIN_BATCH_SIZE,\n",
    "        prefetch_buffer_sz=TRAIN_BATCH_SIZE,\n",
    "    )\n",
    "\n",
    "    test_ds = list_test_ds.map(process_test_path, num_parallel_calls=4)\n",
    "    test_ds = test_ds.batch(TEST_BATCH_SIZE)\n",
    "    test_ds = test_ds.prefetch(buffer_size=10 * TRAIN_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780a707a",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28b51e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cil_mobile\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "img_input (InputLayer)          [(None, 96, 256, 3)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 48, 128, 32)  2432        img_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 48, 128, 32)  128         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 48, 128, 32)  0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 24, 64, 64)   18496       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 24, 64, 64)   256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 24, 64, 64)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 12, 32, 96)   55392       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 12, 32, 96)   384         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 12, 32, 96)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 6, 16, 128)   110720      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 6, 16, 128)   512         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 6, 16, 128)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 3, 8, 256)    295168      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 3, 8, 256)    1024        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 3, 8, 256)    0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 6144)         0           dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          786560      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 128)          512         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "cmd_input (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 128)          0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "cmd (Dense)                     (None, 16)           32          cmd_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           8256        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 16)           0           cmd[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64)           256         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 16)           272         dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 64)           0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 80)           0           dense[0][0]                      \n",
      "                                                                 dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 64)           5184        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 64)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 65)           0           cmd_input[0][0]                  \n",
      "                                                                 dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 16)           1056        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 16)           0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 17)           0           cmd_input[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 2)            36          concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,286,676\n",
      "Trainable params: 1,285,140\n",
      "Non-trainable params: 1,536\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelsantos/anaconda3/envs/openbot/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from openbot import callbacks, losses, metrics, models\n",
    "\n",
    "model = models.cil_mobile(NETWORK_IMG_WIDTH,NETWORK_IMG_HEIGHT,BN)\n",
    "loss_fn = losses.sq_weighted_mse_angle \n",
    "metric_list = ['MeanAbsoluteError', metrics.direction_metric, metrics.angle_metric]\n",
    "optimizer = tf.keras.optimizers.Adam(lr=LR)\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "          loss=loss_fn, \n",
    "          metrics=metric_list)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac509d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_openbot_cil_mobile_lr0.0001_bz16_bn\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = dataset_name + \"_\" + model.name + \"_lr\" + str(LR) + \"_bz\" + str(TRAIN_BATCH_SIZE)\n",
    "if BN:\n",
    "    MODEL_NAME += \"_bn\"\n",
    "if FLIP_AUG:\n",
    "    MODEL_NAME += \"_flip\"\n",
    "if CMD_AUG:\n",
    "    MODEL_NAME += \"_cmd\"    \n",
    "    \n",
    "checkpoint_path = os.path.join('models', MODEL_NAME, 'checkpoints')\n",
    "log_path = os.path.join('models',MODEL_NAME,'logs')\n",
    "print(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d0b8ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-17 10:13:55.351718: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1661] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  2/955 [..............................] - ETA: 2:55 - loss: 0.1912 - mean_absolute_error: 1.7412 - direction_metric: 0.0625 - angle_metric: 0.0000e+00 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-17 10:13:57.207600: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1661] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 91/955 [=>............................] - ETA: 1:48 - loss: 0.4595 - mean_absolute_error: 1.8052 - direction_metric: 0.1717 - angle_metric: 0.0330"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13678/1855765044.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mSTEPS_PER_EPOCH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_count_train\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mTRAIN_BATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m history = model.fit(train_ds, \n\u001b[0m\u001b[1;32m      3\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSTEPS_PER_EPOCH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/openbot/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/openbot/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/openbot/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/openbot/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/openbot/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/envs/openbot/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/openbot/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "STEPS_PER_EPOCH = np.ceil(image_count_train / TRAIN_BATCH_SIZE)\n",
    "history = model.fit(train_ds, \n",
    "                    epochs=NUM_EPOCHS, \n",
    "                    steps_per_epoch=STEPS_PER_EPOCH, \n",
    "                    validation_data=test_ds, \n",
    "                    callbacks=[callbacks.checkpoint_cb(checkpoint_path),\n",
    "                               callbacks.tensorboard_cb(log_path),\n",
    "                               callbacks.logger_cb(log_path)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11459d7",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d8eb59",
   "metadata": {},
   "source": [
    "Plot metrics and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc85fb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['MeanAbsoluteError'], label='mean_absolute_error')\n",
    "plt.plot(history.history['val_MeanAbsoluteError'], label = 'val_mean_absolute_error')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig(os.path.join(log_path,'error.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ec8cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['direction_metric'], label='direction_metric')\n",
    "plt.plot(history.history['val_direction_metric'], label = 'val_direction_metric')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Direction Metric')\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig(os.path.join(log_path,'direction.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2ae85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['angle_metric'], label='angle_metric')\n",
    "plt.plot(history.history['val_angle_metric'], label = 'val_angle_metric')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Angle Metric')\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig(os.path.join(log_path,'angle.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9d3c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label = 'val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig(os.path.join(log_path,'loss.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebee4708",
   "metadata": {},
   "source": [
    "Save tf lite models for best and last checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f498f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_index = np.argmax(np.array(history.history['val_angle_metric']) \\\n",
    "                     + np.array(history.history['val_direction_metric']))\n",
    "best_checkpoint = str(\"cp-%04d.ckpt\" % (best_index+1))\n",
    "best_tflite = utils.generate_tflite(checkpoint_path, best_checkpoint)\n",
    "utils.save_tflite (best_tflite, checkpoint_path, \"best\")\n",
    "print(\"Best Checkpoint (val_angle: %s, val_direction: %s): %s\" \\\n",
    "      %(history.history['val_angle_metric'][best_index],\\\n",
    "        history.history['val_direction_metric'][best_index],\\\n",
    "        best_checkpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5810ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_checkpoint = sorted([d for d in os.listdir(checkpoint_path) if os.path.isdir(os.path.join(checkpoint_path, d))])[-1]\n",
    "last_tflite = utils.generate_tflite(checkpoint_path, last_checkpoint)\n",
    "utils.save_tflite (last_tflite, checkpoint_path, \"last\")\n",
    "print(\"Last Checkpoint (val_angle: %s, val_direction: %s): %s\" \\\n",
    "      %(history.history['val_angle_metric'][-1], \\\n",
    "        history.history['val_direction_metric'][-1], \\\n",
    "        last_checkpoint))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e39ac71",
   "metadata": {},
   "source": [
    "Evaluate the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e177c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = utils.load_model(os.path.join(checkpoint_path,best_checkpoint),loss_fn,metric_list)\n",
    "test_loss, test_acc, test_dir, test_ang = best_model.evaluate(test_ds, steps=image_count_test/TEST_BATCH_SIZE, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cbf2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SAMPLES = 15\n",
    "(image_batch, cmd_batch), label_batch = next(iter(test_ds))\n",
    "pred_batch = best_model.predict( (tf.slice(image_batch, [0, 0, 0, 0], [NUM_SAMPLES, -1, -1, -1]), tf.slice(cmd_batch, [0], [NUM_SAMPLES])) )\n",
    "utils.show_test_batch(image_batch.numpy(), cmd_batch.numpy(), label_batch.numpy(), pred_batch)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af8f410",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.compare_tf_tflite(best_model,best_tflite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abd37cf",
   "metadata": {},
   "source": [
    "## Save the notebook as HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b0c5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.save_notebook()\n",
    "current_file = 'policy_learning.ipynb'\n",
    "output_file = os.path.join(log_path,'notebook.html')\n",
    "utils.output_HTML(current_file, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
